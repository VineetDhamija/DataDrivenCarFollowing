{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing required libraries to predict acceleration using random forest, calculate RMSE (RootMeanSquaredError), and create plots to compare predicted and actual acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import src\n",
    "import FileProcessing\n",
    "import ModelClass\n",
    "from asyncio.windows_events import NULL\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, MaxPooling2D, Bidirectional, LSTM, RepeatVector, Dense, TimeDistributed # for creating layers inside the Neural Network\n",
    "\n",
    "import tensorflow\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import FileProcessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef fit_and_run_neural(df, time_frame):\\n        shift_instance = time_frame*10\\n        df, train_df, val_df, test_df, X_train, y_train, X_val, y_val, X_test, y_test = model_obj.preprocessing(\\n            df, shift_instance)\\n        model = model_obj.define_neural_network(X_train)\\n        model = model_obj.fit_neural_network(\\n            model, X_train, y_train, X_val, y_val, time_frame)\\n        predict_on_pair = model_obj.prediction_test_pairs(test_df, 10, 12)\\n        predict_on_pair[0]\\n        print(f\"Prediction being done on :{predict_on_pair[0]}\")\\n        target_variable = \\'nextframeAcc\\'\\n        return df, train_df, val_df, test_df, X_train, y_train, X_val, y_val, X_test, y_test, model\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def fit_and_run_neural(df, time_frame):\n",
    "        shift_instance = time_frame*10\n",
    "        df, train_df, val_df, test_df, X_train, y_train, X_val, y_val, X_test, y_test = model_obj.preprocessing(\n",
    "            df, shift_instance)\n",
    "        model = model_obj.define_neural_network(X_train)\n",
    "        model = model_obj.fit_neural_network(\n",
    "            model, X_train, y_train, X_val, y_val, time_frame)\n",
    "        predict_on_pair = model_obj.prediction_test_pairs(test_df, 10, 12)\n",
    "        predict_on_pair[0]\n",
    "        print(f\"Prediction being done on :{predict_on_pair[0]}\")\n",
    "        target_variable = 'nextframeAcc'\n",
    "        return df, train_df, val_df, test_df, X_train, y_train, X_val, y_val, X_test, y_test, model\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the cleaned ngsim data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileProcessing=FileProcessing.FileProcessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj=ModelClass.ModelClass()\n",
    "file=FileProcessing.FileProcessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original File path: C:\\Users\\StudentAccount\\Python\\Capstone\\gitcodelocation\\DataDrivenCarFollowing\\datadrivencarfollowing-v1\\scripts\n",
      "Data File path: C:\\Users\\StudentAccount\\Python\\Capstone\\gitcodelocation\\DataDrivenCarFollowing\\datadrivencarfollowing-v1\\data\n"
     ]
    }
   ],
   "source": [
    "file_name='Cleaned_NGSIM_Data'\n",
    "ngsim=fileProcessing.read_input(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_ngsim=ngsim[((ngsim['L-F_Pair'] == '422-427' ) )]\n",
    "#fileProcessing.export_file(filtered_ngsim,'verify_cleaned_file')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfile_name='Next_Generation_Simulation__NGSIM__Vehicle_Trajectories_and_Supporting_Data'\\nngsim=fileProcessing.read_input(file_name)\\nfiltered_ngsim=ngsim[((ngsim['Vehicle_ID'] == 422 )| (ngsim['Vehicle_ID'] == 427) )]\\nfileProcessing.export_file(filtered_ngsim,'verify_ngsim_file')\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "file_name='Next_Generation_Simulation__NGSIM__Vehicle_Trajectories_and_Supporting_Data'\n",
    "ngsim=fileProcessing.read_input(file_name)\n",
    "filtered_ngsim=ngsim[((ngsim['Vehicle_ID'] == 422 )| (ngsim['Vehicle_ID'] == 427) )]\n",
    "fileProcessing.export_file(filtered_ngsim,'verify_ngsim_file')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_run_lstm(df, time_frame):\n",
    "    shift_instance = time_frame*10\n",
    "    df, train_df, val_df, test_df, X_train, y_train, X_val, y_val, X_test, y_test = model_obj.preprocessing(df, shift_instance)\n",
    "    return df, train_df, val_df, test_df, X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_lstm( input_df):\n",
    "    # input = keras.Input(shape=(18,))\n",
    "    print(input_df.shape)\n",
    "    #input_df = tensorflow.expand_dims(input_df, axis=-1)\n",
    "    input_df = tensorflow.expand_dims(input_df, axis=-1)\n",
    "    print(input_df.shape)\n",
    "    #input = keras.Input(shape=(input_df.shape[1], ))\n",
    "\n",
    "    #input = keras.Input(shape=(input_df.shape[1], ), dtype=\"float64\")\n",
    "    inputs = keras.Input(shape=(input_df.shape[1],), dtype=\"float64\")\n",
    "    x = layers.Bidirectional(layers.LSTM(\n",
    "        128, return_sequences=True))(inputs)\n",
    "    x = layers.MaxPooling1D()(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    outputs = layers.Dense(1, activation=\"elu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                    loss=\"binary_crossentropy\",\n",
    "                    metrics=[\"accuracy\"])\n",
    "\n",
    "    x = layers.LSTM(128, activation='elu', use_bias=True,\n",
    "                    dropout=0.2, return_state=True)(input)\n",
    "    x = layers.LSTM(128, activation='elu', use_bias=True,\n",
    "                    dropout=0.2, return_state=True)(x)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_time=0.1\n",
    "ngsim_1, train_df_1, val_df_1, test_df_1, X_train_1, y_train_1, X_val_1, y_val_1, X_test_1, y_test_1= fit_and_run_lstm(ngsim, delta_time)\n",
    "#model = define_lstm(X_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BatchDataset' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43minput_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BatchDataset' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "#input_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"bidirectional_4\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m inputs \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#x = layers.Embedding(5,5,embeddings_initializer='uniform')(inputs)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBidirectional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mMaxPooling1D()(x)\n\u001b[0;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mBidirectional(layers\u001b[38;5;241m.\u001b[39mLSTM(\u001b[38;5;241m64\u001b[39m))(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Project-tensor\\lib\\site-packages\\keras\\layers\\rnn\\bidirectional.py:249\u001b[0m, in \u001b[0;36mBidirectional.__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m constants \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 249\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(Bidirectional, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# Applies the same workaround as in `RNN.__call__`\u001b[39;00m\n\u001b[0;32m    252\u001b[0m additional_inputs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Project-tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Project-tensor\\lib\\site-packages\\keras\\engine\\input_spec.py:214\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    212\u001b[0m   ndim \u001b[38;5;241m=\u001b[39m shape\u001b[38;5;241m.\u001b[39mrank\n\u001b[0;32m    213\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m!=\u001b[39m spec\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    215\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    216\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, found ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    217\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mmax_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    219\u001b[0m   ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"bidirectional_4\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 5)"
     ]
    }
   ],
   "source": [
    "#print(input_df.shape)\n",
    "#input_df = tensorflow.expand_dims(input_df, axis=-1)\n",
    "#print(input_df.shape)\n",
    "\n",
    "#inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "inputs = keras.Input(shape=(5,), dtype=\"int64\")\n",
    "\n",
    "#x = layers.Embedding(5,5,embeddings_initializer='uniform')(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(inputs)\n",
    "x = layers.MaxPooling1D()(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"elu\")(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "                loss=\"binary_crossentropy\",\n",
    "                metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "#    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngsim=ngsim_1\n",
    "train_df= train_df_1\n",
    "val_df=val_df_1,\n",
    "test_df= test_df_1\n",
    "X_train= X_train_1\n",
    "y_train=y_train_1\n",
    "X_val=X_val_1\n",
    "y_val=y_val_1\n",
    "X_test=X_test_1\n",
    "y_test=y_test_1\n",
    "#model.fit(int_train_ds, validation_data=int_val_ds,\n",
    "time_frame=delta_time\n",
    "reaction_time=delta_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef fit_lstm(model, train_df, val_df, reaction_time):\\n    modelName = \"lstm_model\" + str(reaction_time) + \".keras\"\\n    save_callback = keras.callbacks.ModelCheckpoint(\\n        modelName, save_best_only=True)\\n    early_stopping = keras.callbacks.EarlyStopping(\\n        monitor=\\'val_accuracy\\', verbose=1, patience=7)\\n    history=model.fit(train_df, validation_data=val_df, epochs=20,callbacks=[save_callback,early_stopping])\\n    #history = model.fit(train_df, epochs=1, batch_size=16,\\n    #                    verbose=1, validation_data=val_df, callbacks=[save_callback, early_stopping])\\n    # convertingt the accuracy of the model to a graph.\\n    # the dictionary that has the information on loss and accuracy per epoch\\n    history_dict = history.history\\n\\n    loss_values = history_dict[\\'loss\\']   # training loss\\n    val_loss_values = history_dict[\\'val_loss\\']  # validation loss\\n\\n    # creates list of integers to match the number of epochs of training\\n    epochs = range(1, len(loss_values)+1)\\n\\n    # code to plot the results\\n    plt.plot(epochs, loss_values, \\'b\\', label=\"Training Loss\")\\n    plt.plot(epochs, val_loss_values, \\'r\\', label=\"Validation Loss\")\\n    plt.title(\"Training and Validation Loss\")\\n    plt.xlabel(\"Epochs\")\\n    plt.xticks(epochs)\\n    plt.ylabel(\"Loss\")\\n    plt.legend()\\n    plt.show()\\n    # As above, but this time we want to visualize the training and validation accuracy\\n    acc_values = history_dict[\\'accuracy\\']\\n    val_acc_values = history_dict[\\'val_accuracy\\']\\n\\n    plt.plot(epochs, acc_values, \\'b\\', label=\"Training Accuracy\")\\n    plt.plot(epochs, val_acc_values, \\'r\\', label=\"Validation Accuracy\")\\n    plt.title(\"Training and Validation Accuracy\")\\n    plt.xlabel(\"Epochs\")\\n    plt.xticks(epochs)\\n    plt.ylabel(\"Accuracy\")\\n    plt.legend()\\n    plt.show()\\n    return model\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def fit_lstm(model, train_df, val_df, reaction_time):\n",
    "    modelName = \"lstm_model\" + str(reaction_time) + \".keras\"\n",
    "    save_callback = keras.callbacks.ModelCheckpoint(\n",
    "        modelName, save_best_only=True)\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', verbose=1, patience=7)\n",
    "    history=model.fit(train_df, validation_data=val_df, epochs=20,callbacks=[save_callback,early_stopping])\n",
    "    #history = model.fit(train_df, epochs=1, batch_size=16,\n",
    "    #                    verbose=1, validation_data=val_df, callbacks=[save_callback, early_stopping])\n",
    "    # convertingt the accuracy of the model to a graph.\n",
    "    # the dictionary that has the information on loss and accuracy per epoch\n",
    "    history_dict = history.history\n",
    "\n",
    "    loss_values = history_dict['loss']   # training loss\n",
    "    val_loss_values = history_dict['val_loss']  # validation loss\n",
    "\n",
    "    # creates list of integers to match the number of epochs of training\n",
    "    epochs = range(1, len(loss_values)+1)\n",
    "\n",
    "    # code to plot the results\n",
    "    plt.plot(epochs, loss_values, 'b', label=\"Training Loss\")\n",
    "    plt.plot(epochs, val_loss_values, 'r', label=\"Validation Loss\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.xticks(epochs)\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # As above, but this time we want to visualize the training and validation accuracy\n",
    "    acc_values = history_dict['accuracy']\n",
    "    val_acc_values = history_dict['val_accuracy']\n",
    "\n",
    "    plt.plot(epochs, acc_values, 'b', label=\"Training Accuracy\")\n",
    "    plt.plot(epochs, val_acc_values, 'r', label=\"Validation Accuracy\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.xticks(epochs)\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_df=X_train_1\n",
    "\n",
    "train_ds = tensorflow.data.Dataset.from_tensor_slices((X_train_1, y_train_1))\n",
    "input_df = train_ds.batch(32)\n",
    "\n",
    "val_ds = tensorflow.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_df = val_ds.batch(32)\n",
    "\n",
    "int_train_ds = train_ds.map(\n",
    "    lambda x, y: (x, y))\n",
    "\n",
    "int_val_ds = val_ds.map(\n",
    "    lambda x, y: (x, y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 5) for input KerasTensor(type_spec=TensorSpec(shape=(None, 5), dtype=tf.int64, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (5,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\StudentAccount\\anaconda3\\envs\\Project-tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\StudentAccount\\anaconda3\\envs\\Project-tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\StudentAccount\\anaconda3\\envs\\Project-tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\StudentAccount\\anaconda3\\envs\\Project-tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\StudentAccount\\anaconda3\\envs\\Project-tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\StudentAccount\\anaconda3\\envs\\Project-tensor\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 214, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"model_1\" (type Functional).\n    \n    Input 0 of layer \"bidirectional_2\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (5, 5)\n    \n    Call arguments received by layer \"model_1\" (type Functional):\n      • inputs=tf.Tensor(shape=(5,), dtype=float64)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m save_callback \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[0;32m      5\u001b[0m     modelName, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[0;32m      7\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m history\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mint_train_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mint_val_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msave_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#history = model.fit(train_df, epochs=1, batch_size=16,\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#                    verbose=1, validation_data=val_df, callbacks=[save_callback, early_stopping])\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# convertingt the accuracy of the model to a graph.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# the dictionary that has the information on loss and accuracy per epoch\u001b[39;00m\n\u001b[0;32m     13\u001b[0m history_dict \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Project-tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\STUDEN~1\\AppData\\Local\\Temp\\__autograph_generated_filek1kj6res.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\StudentAccount\\anaconda3\\envs\\Project-tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\StudentAccount\\anaconda3\\envs\\Project-tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\StudentAccount\\anaconda3\\envs\\Project-tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\StudentAccount\\anaconda3\\envs\\Project-tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\StudentAccount\\anaconda3\\envs\\Project-tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\StudentAccount\\anaconda3\\envs\\Project-tensor\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 214, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"model_1\" (type Functional).\n    \n    Input 0 of layer \"bidirectional_2\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (5, 5)\n    \n    Call arguments received by layer \"model_1\" (type Functional):\n      • inputs=tf.Tensor(shape=(5,), dtype=float64)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "#model = fit_lstm(model, int_train_ds,int_val_ds, time_frame)\n",
    "\n",
    "modelName = \"lstm_model\" + str(reaction_time) + \".keras\"\n",
    "save_callback = keras.callbacks.ModelCheckpoint(\n",
    "    modelName, save_best_only=True)\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', verbose=1, patience=7)\n",
    "history=model.fit(int_train_ds, validation_data=int_val_ds, epochs=20,callbacks=[save_callback,early_stopping])\n",
    "#history = model.fit(train_df, epochs=1, batch_size=16,\n",
    "#                    verbose=1, validation_data=val_df, callbacks=[save_callback, early_stopping])\n",
    "# convertingt the accuracy of the model to a graph.\n",
    "# the dictionary that has the information on loss and accuracy per epoch\n",
    "history_dict = history.history\n",
    "\n",
    "loss_values = history_dict['loss']   # training loss\n",
    "val_loss_values = history_dict['val_loss']  # validation loss\n",
    "\n",
    "# creates list of integers to match the number of epochs of training\n",
    "epochs = range(1, len(loss_values)+1)\n",
    "\n",
    "# code to plot the results\n",
    "plt.plot(epochs, loss_values, 'b', label=\"Training Loss\")\n",
    "plt.plot(epochs, val_loss_values, 'r', label=\"Validation Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(epochs)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# As above, but this time we want to visualize the training and validation accuracy\n",
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc_values, 'b', label=\"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc_values, 'r', label=\"Validation Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(epochs)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict_on_pair = model_obj.prediction_test_pairs(test_df, 10, 12)\n",
    "predict_on_pair[0]\n",
    "print(f\"Prediction being done on :{predict_on_pair[0]}\")\n",
    "target_variable = 'nextframeAcc'\n",
    "predict_on_pair = model_obj.prediction_test_pairs(test_df_1, 10, 12)\n",
    "current_pair=predict_on_pair[0]\n",
    "predict_on_pair=current_pair\n",
    "target_variable = 'nextframeAcc'\n",
    "#current_pair='422-427'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_on_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngsim=ngsim_1\n",
    "train_df= train_df_1\n",
    "val_df=val_df_1,\n",
    "test_df= test_df_1\n",
    "X_train= X_train_1\n",
    "y_train=y_train_1\n",
    "X_val=X_val_1\n",
    "y_val=y_val_1\n",
    "X_test=X_test_1\n",
    "y_test=y_test_1\n",
    "model=model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_range=predict_on_pair\n",
    "\n",
    "predicted_df = []\n",
    "        # this loop runs for each pair required predictions.\n",
    "\n",
    "# Assign shape of the predictions\n",
    "input_df = []\n",
    "input_df = test_df[test_df['L-F_Pair'] == current_pair]\n",
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj.plot_prediction(input_df, 'pair_Time_Duration',\n",
    "                        'predicted_acceleration', 'nextframeAcc', 'Acceleration', delta_time)\n",
    "model_obj.plot_prediction(input_df, 'pair_Time_Duration',\n",
    "                        'predicted_velocity', 'nextframesvel', 'Velocity', delta_time)\n",
    "model_obj.plot_prediction(input_df, 'pair_Time_Duration',\n",
    "                        'predicted_spacing', 'nextFrameSpacing', 'Spacing', delta_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fileProcessing.export_file(input_df,'input_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "32f9b5c64a9ffdfd44c75ce715a0c18d651d70bac5b5e0fedf911a0bbec25f03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
